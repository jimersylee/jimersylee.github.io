<!--
author: Jimersy Lee
head: 
date: 2016-05-22
title: <机器学习实战>学习笔记之NaiveBayes
tags: PYTHON,MACHINE-LEARNING
images: 
category: python
status: publish
summary: 朴素贝叶斯,使用Python进行恶意留言分类,区域分析,垃圾邮件识别
-->

项目地址:[http://github.com/jimersylee/MachineLearningAction](http://github.com/jimersylee/MachineLearningAction)

###基于概率论的分类方法
####朴素贝叶斯
- 使用概率分布进行分类
- 学习朴素贝叶斯分类器
- 解析RSS源数据
- 使用朴素贝叶斯来分析不同地区的态度


####朴素贝叶斯
优点:在数据较少的情况下仍然有效,可以处理多类别问题
缺点:对于输入数据的准备方式较为敏感
使用数据类型:标称型数据


####贝叶斯决策理论的核心思想--即选择具有最高概率的决策


##条件概率

P(A|B)=$$\underline{P(AB)}\\P(B)$$

###使用贝叶斯准则,进行条件与结果的互换计算
已知P(A|B),求P(B|A)

P(B|A)=$$\underline{P(A|B)P(B)}\\P(A)$$


推导
>给定某个点(x,y),那么该点来自$$c_i$$的概率为P($$c_i$$|x,y)

P($$c_i$$|x,y)=$$\underline{P(x,y|c_i)P(c_i)}\\P(x,y)$$

结论
>如果$$P(c_1|x,y)>P(c_2|x,y)$$,那么(x,y)属于$$c_1$$
如果$$P(c_2|x,y)>P(c_1|x,y)$$,那么(x,y)属于$$c_2$$




###使用朴素贝叶斯进行文档分类
朴素贝叶斯是贝叶斯分类器的一个扩展,是用于文档分类的常用算法
朴素贝叶斯的一帮过程
1. 收集数据:可以使用任何方法,本章使用RSS源
2. 准备数据:需要数值型或者布尔型数据
3. 分析数据:有大量特征时,绘制特征作用不大,此时使用直方图效果较好
4. 训练算法:计算不同的独立特征的条件概率
5. 测试算法:计算错误率
6. 使用算法:一个常见的朴素贝叶斯应用是文档分类.可以在任意的分类场景中使用朴素贝叶斯分类器,不一定非要是文本.


假设词汇表有1000个单词,要得到好的概率分布,需要足够的样本,假设样本数为N
>由统计学知,如果每个特征需要N个样本,那么对于x个特征,将需要$$N^x$$个样本

对于1000个特征的词汇表将需要$$N^{1000}$$个样本,可以看到,所需要的样本数会随着特征数目的增大而迅速增长
如果特征之间项目独立,那么样本数就能从$$N^{1000}$$减少到N*1000.所谓独立,指的是**统计学上的独立,即一个特征或者单词出现的可能性与它和其他相邻单词没关系**


####示例:使用Python进行恶意留言分类
当论坛中用户发表评论时,总会存在一些恶意言论,如何识别是否为恶意评论,而不让其发送呢?

1. 准备数据:从文本中构建词向量,详见bayes.py中的 createVocabList setOfWords2Vec
2. 训练算法:从词向量计算概率

重写贝叶斯准则,将之前的x,y替换为*w*,粗体*w*表示一个向量,即它是由多个数值组成.在这个例子中,数值个数与词汇表中的词个数相同
P($$c_i$$|w)=$$\underline{P(w|c_i)P(c_i)}\\P(w)$$
如何计算?首先通过类别i(侮辱性或者非侮辱性留言)中的文档数除以总的文档数的计算概率p($$c_i$$),接下来计算P($$c_i$$|w),这里就用到了朴素贝叶斯假设
>如果将w展开为一个个独立特征,那么可以将上述概率写做P($$w_0$$,$$w_1$$,...,$$w_N$$|$$c_i$$).这里假设所有事件都独立,它意味着可以使用P($$w_0$$|$$c_i$$)P($$w_1$$|$$c_i$$)...P($$w_N$$|$$c_i$$)来计算概率,这极大地简化了计算过程
该函数的伪代码如下
计算每个类别中的文档数目
对每篇训练文档:

对每个类别:
如果词条出现文档中->增加该词条的计数值
增加所有词条的计数值
对每个类别:
对每个词条:
将该词条的数目除以总词条数目得到条件概率
返回每个类别的条件概率


3. 测试算法:根据现实情况修改分类器
    利用贝叶斯分类器进行分类时,要计算多个概率的乘积,如果其中一个概率值为0,那么最后的乘积也是0.为降低这种影响,可以将所有的词的出现数初始化为1,并将分母初始化为2

4. 准备数据:文档词袋模型
    目前为止,我们将每个词的出现与否作为一个特征,这可以被描述为**词集模型(set-of-words-model)**.如果一个词在文档中出现不止一次,这可能意味着包含该词是否出现在文档中所不能表达的某种信息,这种方法被成为**词袋模型(bag-of-words-model)**.在词袋中,每个单词可以出现多次,而在词集中,每个词只出现一次.为适应词袋模型,需要对函数setOfWords2Vec()稍作修改,修改后的函数称为bagOfWords2Vec()



####示例:使用朴素贝叶斯过滤垃圾邮件
邮件经常收到一些广告邮件,如何将广告邮件识别出来呢?

1. 收集数据:提供文本文件
1. 准备数据:将文本解析成词条向量
1. 分析数据:检查词条确保解析的正确性
1. 训练算法:使用我们之前建立的trainNormalBayes0()函数
1. 测试算法:使用classifyNormal(),并且构建一个新的测试函数来计算文档集的错误率
1. 使用算法:构建一个完整的程序对一组文档进行分类,将错误分类的文档输出到屏幕上

####示例:使用朴素贝叶斯分类器从个人广告中获取区域倾向














